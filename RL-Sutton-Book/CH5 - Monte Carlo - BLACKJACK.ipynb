{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](pictures/blackjack.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(2,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initialize\n",
    "number_of_states = 22\n",
    "number_of_actions = 2\n",
    "\n",
    "\n",
    "policy=np.random.randint(0, number_of_actions, number_of_states)\n",
    "Q = np.random.randn(number_of_states, number_of_actions)\n",
    "returns = [[[] for e in range(number_of_actions)] for e in range(number_of_states)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](pictures/mc.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initialize\n",
    "number_of_states = 22\n",
    "number_of_actions = 2\n",
    "gamma = 0.7\n",
    "\n",
    "# card probabilities\n",
    "ps = np.ones(10)\n",
    "ps[-2] += 2\n",
    "ps = ps/np.sum(ps)\n",
    "\n",
    "policy=np.random.randint(0, number_of_actions, number_of_states)\n",
    "Q = np.random.randn(number_of_states, number_of_actions)\n",
    "returns = [[[] for e in range(number_of_actions)] for e in range(number_of_states)]\n",
    "counter = np.zeros_like(Q)\n",
    "\n",
    "#2. Loop\n",
    "\n",
    "for e in range(100000):\n",
    "    s0 = np.random.choice(np.arange(2,12), p = ps) + np.random.choice(np.arange(2,12), p = ps)\n",
    "    a0 = np.random.randint(0,2)\n",
    "    \n",
    "    \n",
    "    #generate episode\n",
    "    s = s0\n",
    "    a = a0\n",
    "    episode = []\n",
    "    r = 0\n",
    "    terminal = s>21 # false\n",
    "    \n",
    "    while not terminal:\n",
    "        \n",
    "        episode.append((s,a))\n",
    "        \n",
    "        if a == 0:\n",
    "            #stick\n",
    "            banker = np.random.choice(np.arange(2,12), p = ps) + np.random.choice(np.arange(2,12), p = ps)\n",
    "            while banker<17:\n",
    "                banker += np.random.choice(np.arange(2,12), p = ps)\n",
    "            if banker < s:\n",
    "                r = +1\n",
    "                if s == 21:\n",
    "                    r = 1.5\n",
    "            if banker > s:\n",
    "                r = -1\n",
    "            if banker == s:\n",
    "                r = 0\n",
    "            if banker > 21:\n",
    "                r = +1\n",
    "            terminal = True\n",
    "        \n",
    "        else:\n",
    "            #one more\n",
    "            s += np.random.choice(np.arange(2,12), p = ps)\n",
    "            if s>21:\n",
    "                #bust\n",
    "                r = -1\n",
    "                terminal = True\n",
    "            else:\n",
    "                a = policy[s]\n",
    "    G = r\n",
    "    for e in range(len(episode)):\n",
    "        i = len(episode) - e -1\n",
    "        G = gamma * G\n",
    "        \n",
    "        s = episode[i][0]\n",
    "        a = episode[i][1]\n",
    "        \n",
    "        counter[s][a] += 1.\n",
    "        #returns[s][a] = (returns[s][a]*(counter[s][a] - 1) + G)/counter[s][a]\n",
    "        Q[s][a] = (Q[s][a]*(counter[s][a] - 1) + G)/counter[s][a]\n",
    "        policy[s] = np.argmax(Q[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The agent found the optimal strategy: settle for anything greater than 13"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
